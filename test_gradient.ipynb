{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Understand\n",
    "\n",
    "Learnings\n",
    "- inputs are [pos, neg] major. So my context extension code was wrong.\n",
    "- Model is indeed causal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange, repeat\n",
    "\n",
    "rearrange(torch.tensor([1, 1, 1, 1, 2, 2, 2, 2]), '(a b)  -> a b', a=2, b=4)  # [1, 2, 3, 4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total VRAM 81229 MB, total RAM 1814232 MB\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA A100-SXM4-80GB : native\n",
      "VAE dtype: torch.bfloat16\n",
      "Using pytorch cross attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/inf/ComfyUI/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 320, 64, 64])\n",
      "Set options: {'force_causal': False, 'force_causal_use_manual_mask': False, 'extend_context': False, 'first_frame_16': False, 'skip_vanilla_temporal_module': False, 'save_motion_module': False, 'auto_step_batch_offset': False, 'print_motion_module': False, 'print_model': False, 'offset_positional_encoding': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.004833221435546875),\n",
       " (1, 0.00525665283203125),\n",
       " (2, 0.007843017578125),\n",
       " (3, 0.011474609375),\n",
       " (4, 0.00963592529296875),\n",
       " (5, 0.006561279296875),\n",
       " (6, 0.00496673583984375),\n",
       " (7, 0.0101776123046875),\n",
       " (8, 0.98681640625),\n",
       " (9, 0.046630859375),\n",
       " (10, 0.0249481201171875),\n",
       " (11, 0.0179290771484375),\n",
       " (12, 0.006786346435546875),\n",
       " (13, 0.004302978515625),\n",
       " (14, 0.00522613525390625),\n",
       " (15, 0.00441741943359375),\n",
       " (16, 0.0),\n",
       " (17, 0.0),\n",
       " (18, 0.0),\n",
       " (19, 0.0),\n",
       " (20, 0.0),\n",
       " (21, 0.0),\n",
       " (22, 0.0),\n",
       " (23, 0.0),\n",
       " (24, 0.0),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (28, 0.0),\n",
       " (29, 0.0),\n",
       " (30, 0.0),\n",
       " (31, 0.0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import surgery\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), \"ComfyUI\", \"custom_nodes\"))\n",
    "\n",
    "vtm = torch.load('vanilla_temporal_module_self.pt')\n",
    "encoder_hidden_states = torch.load('vanilla_temporal_module_encoder_hidden_states.pt')\n",
    "attention_mask = torch.load('vanilla_temporal_module_attention_mask.pt')\n",
    "\n",
    "input_tensor = torch.load('vanilla_temporal_module_input_tensor.pt')\n",
    "print(input_tensor.shape)\n",
    "\n",
    "def get_frame_grads(output_index, force_causal):\n",
    "    surgery.debug_options.set_from_dict({\n",
    "        \"force_causal\": force_causal,\n",
    "    })\n",
    "    input_tensor = torch.load('vanilla_temporal_module_input_tensor.pt')\n",
    "    input_tensor.requires_grad_()\n",
    "    output_tensor = vtm.forward(input_tensor, encoder_hidden_states, attention_mask)\n",
    "    output_tensor[output_index].max().backward()\n",
    "    return [ (i, frame_grad.max().item()) for i, frame_grad in enumerate(input_tensor.grad)]\n",
    "\n",
    "\n",
    "# gradient should be nonzero for future frames (i > 8) bc non-causal\n",
    "get_frame_grads(8, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set options: {'force_causal': True, 'force_causal_use_manual_mask': False, 'extend_context': False, 'first_frame_16': False, 'skip_vanilla_temporal_module': False, 'save_motion_module': False, 'auto_step_batch_offset': False, 'print_motion_module': False, 'print_model': False, 'offset_positional_encoding': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.017333984375),\n",
       " (1, 0.0175628662109375),\n",
       " (2, 0.0150909423828125),\n",
       " (3, 0.02435302734375),\n",
       " (4, 0.02313232421875),\n",
       " (5, 0.0156402587890625),\n",
       " (6, 0.0164031982421875),\n",
       " (7, 0.01525115966796875),\n",
       " (8, 0.98388671875),\n",
       " (9, 0.0),\n",
       " (10, 0.0),\n",
       " (11, 0.0),\n",
       " (12, 0.0),\n",
       " (13, 0.0),\n",
       " (14, 0.0),\n",
       " (15, 0.0),\n",
       " (16, 0.0),\n",
       " (17, 0.0),\n",
       " (18, 0.0),\n",
       " (19, 0.0),\n",
       " (20, 0.0),\n",
       " (21, 0.0),\n",
       " (22, 0.0),\n",
       " (23, 0.0),\n",
       " (24, 0.0),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (28, 0.0),\n",
       " (29, 0.0),\n",
       " (30, 0.0),\n",
       " (31, 0.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we throw on the causal mask, the gradient should be zero for future frames\n",
    "get_frame_grads(8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set options: {'force_causal': True, 'force_causal_use_manual_mask': False, 'extend_context': False, 'first_frame_16': False, 'skip_vanilla_temporal_module': False, 'save_motion_module': False, 'auto_step_batch_offset': False, 'print_motion_module': False, 'print_model': False, 'offset_positional_encoding': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.0),\n",
       " (1, 0.0),\n",
       " (2, 0.0),\n",
       " (3, 0.0),\n",
       " (4, 0.0),\n",
       " (5, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (8, 0.0),\n",
       " (9, 0.0),\n",
       " (10, 0.0),\n",
       " (11, 0.0),\n",
       " (12, 0.0),\n",
       " (13, 0.0),\n",
       " (14, 0.0),\n",
       " (15, 0.0),\n",
       " (16, 0.0169830322265625),\n",
       " (17, 0.01751708984375),\n",
       " (18, 0.01493072509765625),\n",
       " (19, 0.024139404296875),\n",
       " (20, 0.023193359375),\n",
       " (21, 0.01538848876953125),\n",
       " (22, 0.016204833984375),\n",
       " (23, 0.01464080810546875),\n",
       " (24, 0.9833984375),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (28, 0.0),\n",
       " (29, 0.0),\n",
       " (30, 0.0),\n",
       " (31, 0.0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another thing is that the data is channel major\n",
    "# You can see the gradients do not flow across channels\n",
    "get_frame_grads(16 + 8, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
